{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "267f5b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import chi2_contingency\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
    "import warnings\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ba7f36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = pd.read_excel(\"C:\\\\Users\\\\akank\\\\OneDrive - University of Cincinnati\\\\Practice\\\\Machine Learning\\\\Credit Lending\\\\case_study1.xlsx\")\n",
    "a2 = pd.read_excel(\"C:\\\\Users\\\\akank\\\\OneDrive - University of Cincinnati\\\\Practice\\\\Machine Learning\\\\Credit Lending\\\\case_study2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba8a319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = a1.copy()\n",
    "df2 = a2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "046914d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing null values\n",
    "df1 = df1.loc[df1['Age_Oldest_TL'] != -99999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40e7dd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_be_removed = []\n",
    "\n",
    "for i in df2.columns:\n",
    "    if df2.loc[df2[i] == -99999].shape[0] > 10000:\n",
    "        columns_to_be_removed .append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e885264b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop(columns_to_be_removed, axis =1)\n",
    "\n",
    "\n",
    "\n",
    "for i in df2.columns:\n",
    "    df2 = df2.loc[ df2[i] != -99999 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01f8579c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROSPECTID\n"
     ]
    }
   ],
   "source": [
    "# Checking common column names\n",
    "for i in list(df1.columns):\n",
    "    if i in list(df2.columns):\n",
    "        print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5df8faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes, inner join so that no nulls are present\n",
    "df = pd. merge ( df1, df2, how ='inner', left_on = ['PROSPECTID'], right_on = ['PROSPECTID'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48dd6599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARITALSTATUS\n",
      "EDUCATION\n",
      "GENDER\n",
      "last_prod_enq2\n",
      "first_prod_enq2\n",
      "Approved_Flag\n"
     ]
    }
   ],
   "source": [
    "# check how many columns are categorical\n",
    "for i in df.columns:\n",
    "    if df[i].dtype == 'object':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdb72397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARITALSTATUS --- 3.578180861038862e-233\n",
      "EDUCATION --- 2.6942265249737532e-30\n",
      "GENDER --- 1.907936100186563e-05\n",
      "last_prod_enq2 --- 0.0\n",
      "first_prod_enq2 --- 7.84997610555419e-287\n"
     ]
    }
   ],
   "source": [
    "# Chi-square test\n",
    "for i in ['MARITALSTATUS', 'EDUCATION', 'GENDER', 'last_prod_enq2', 'first_prod_enq2']:\n",
    "    chi2, pval, _, _ = chi2_contingency(pd.crosstab(df[i], df['Approved_Flag']))\n",
    "    print(i, '---', pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bf0d08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIF for numerical columns\n",
    "numeric_columns = []\n",
    "for i in df.columns:\n",
    "    if df[i].dtype != 'object' and i not in ['PROSPECTID','Approved_Flag']:\n",
    "        numeric_columns.append(i)\n",
    "\n",
    "\n",
    "\n",
    "      \n",
    "\n",
    "#VIF sequentially check\n",
    "\n",
    "vif_data = df[numeric_columns]\n",
    "total_columns = vif_data.shape[1]\n",
    "columns_to_be_kept = []\n",
    "column_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbc1b7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akank\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --- inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akank\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --- inf\n",
      "0 --- 11.320180023967996\n",
      "0 --- 8.363698035000336\n",
      "0 --- 6.520647877790928\n",
      "0 --- 5.149501618212625\n",
      "1 --- 2.611111040579735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akank\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 --- inf\n",
      "2 --- 1788.7926256209232\n",
      "2 --- 8.601028256477228\n",
      "2 --- 3.8328007921530785\n",
      "3 --- 6.099653381646731\n",
      "3 --- 5.581352009642762\n",
      "4 --- 1.9855843530987785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akank\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 --- inf\n",
      "5 --- 4.809538302819343\n",
      "6 --- 23.270628983464636\n",
      "6 --- 30.595522588100053\n",
      "6 --- 4.3843464059655854\n",
      "7 --- 3.064658415523423\n",
      "8 --- 2.898639771299253\n",
      "9 --- 4.377876915347322\n",
      "10 --- 2.2078535836958433\n",
      "11 --- 4.916914200506864\n",
      "12 --- 5.214702030064725\n",
      "13 --- 3.3861625024231476\n",
      "14 --- 7.840583309478997\n",
      "14 --- 5.255034641721438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akank\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 --- inf\n",
      "15 --- 7.380634506427232\n",
      "15 --- 1.421005001517573\n",
      "16 --- 8.083255010190316\n",
      "16 --- 1.6241227524040112\n",
      "17 --- 7.257811920140003\n",
      "17 --- 15.59624383268298\n",
      "17 --- 1.8258570471324318\n",
      "18 --- 1.5080839450032661\n",
      "19 --- 2.172088834824578\n",
      "20 --- 2.623397553527229\n",
      "21 --- 2.2959970812106176\n",
      "22 --- 7.360578319196446\n",
      "22 --- 2.1602387773102554\n",
      "23 --- 2.8686288267891467\n",
      "24 --- 6.458218003637272\n",
      "24 --- 2.8474118865638265\n",
      "25 --- 4.7531981562840855\n",
      "26 --- 16.22735475594825\n",
      "26 --- 6.424377256363877\n",
      "26 --- 8.887080381808687\n",
      "26 --- 2.3804746142952653\n",
      "27 --- 8.609513476514548\n",
      "27 --- 13.06755093547673\n",
      "27 --- 3.5000400566546555\n",
      "28 --- 1.9087955874813765\n",
      "29 --- 17.006562234161628\n",
      "29 --- 10.730485153719197\n",
      "29 --- 2.3538497522950275\n",
      "30 --- 22.104855915136433\n",
      "30 --- 2.7971639638512906\n",
      "31 --- 3.424171203217697\n",
      "32 --- 10.175021454450922\n",
      "32 --- 6.408710354561301\n",
      "32 --- 1.0011511962625617\n",
      "33 --- 3.069197305397274\n",
      "34 --- 2.8091261600643715\n",
      "35 --- 20.249538381980678\n",
      "35 --- 15.864576541593774\n",
      "35 --- 1.8331649740532168\n",
      "36 --- 1.5680839909542044\n",
      "37 --- 1.9307572353811677\n",
      "38 --- 4.331265056645247\n",
      "39 --- 9.390334396150173\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,total_columns):\n",
    "    \n",
    "    vif_value = variance_inflation_factor(vif_data, column_index)\n",
    "    print (column_index,'---',vif_value)\n",
    "    \n",
    "    \n",
    "    if vif_value <= 6:\n",
    "        columns_to_be_kept.append( numeric_columns[i] )\n",
    "        column_index = column_index+1\n",
    "    \n",
    "    else:\n",
    "        vif_data = vif_data.drop([ numeric_columns[i] ] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6427d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check Anova for columns_to_be_kept \n",
    "\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "columns_to_be_kept_numerical = []\n",
    "\n",
    "for i in columns_to_be_kept:\n",
    "    a = list(df[i])  \n",
    "    b = list(df['Approved_Flag'])  \n",
    "    \n",
    "    group_P1 = [value for value, group in zip(a, b) if group == 'P1']\n",
    "    group_P2 = [value for value, group in zip(a, b) if group == 'P2']\n",
    "    group_P3 = [value for value, group in zip(a, b) if group == 'P3']\n",
    "    group_P4 = [value for value, group in zip(a, b) if group == 'P4']\n",
    "\n",
    "\n",
    "    f_statistic, p_value = f_oneway(group_P1, group_P2, group_P3, group_P4)\n",
    "\n",
    "    if p_value <= 0.05:\n",
    "        columns_to_be_kept_numerical.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5969be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pct_tl_open_L6M',\n",
       " 'pct_tl_closed_L6M',\n",
       " 'Tot_TL_closed_L12M',\n",
       " 'pct_tl_closed_L12M',\n",
       " 'Tot_Missed_Pmnt',\n",
       " 'CC_TL',\n",
       " 'Home_TL',\n",
       " 'PL_TL',\n",
       " 'Secured_TL',\n",
       " 'Unsecured_TL',\n",
       " 'Other_TL',\n",
       " 'Age_Oldest_TL',\n",
       " 'Age_Newest_TL',\n",
       " 'time_since_recent_payment',\n",
       " 'max_recent_level_of_deliq',\n",
       " 'num_deliq_6_12mts',\n",
       " 'num_times_60p_dpd',\n",
       " 'num_std_12mts',\n",
       " 'num_sub',\n",
       " 'num_sub_6mts',\n",
       " 'num_sub_12mts',\n",
       " 'num_dbt',\n",
       " 'num_dbt_12mts',\n",
       " 'num_lss',\n",
       " 'recent_level_of_deliq',\n",
       " 'CC_enq_L12m',\n",
       " 'PL_enq_L12m',\n",
       " 'time_since_recent_enq',\n",
       " 'enq_L3m',\n",
       " 'NETMONTHLYINCOME',\n",
       " 'Time_With_Curr_Empr',\n",
       " 'CC_Flag',\n",
       " 'PL_Flag',\n",
       " 'pct_PL_enq_L6m_of_ever',\n",
       " 'pct_CC_enq_L6m_of_ever',\n",
       " 'HL_Flag',\n",
       " 'GL_Flag']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_be_kept_numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cf8149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# listing all the final features\n",
    "features = columns_to_be_kept_numerical + ['MARITALSTATUS', 'EDUCATION', 'GENDER', 'last_prod_enq2', 'first_prod_enq2']\n",
    "df = df[features + ['Approved_Flag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba1e3b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MARITALSTATUS', 'EDUCATION', 'GENDER', 'last_prod_enq2', 'first_prod_enq2']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label encoding for the categorical features\n",
    "['MARITALSTATUS', 'EDUCATION', 'GENDER' , 'last_prod_enq2' ,'first_prod_enq2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bee83e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PL', 'ConsumerLoan', 'others', 'AL', 'HL', 'CC'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MARITALSTATUS'].unique()    \n",
    "df['EDUCATION'].unique()\n",
    "df['GENDER'].unique()\n",
    "df['last_prod_enq2'].unique()\n",
    "df['first_prod_enq2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62907bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['EDUCATION'] == 'SSC',['EDUCATION']]              = 1\n",
    "df.loc[df['EDUCATION'] == '12TH',['EDUCATION']]             = 2\n",
    "df.loc[df['EDUCATION'] == 'GRADUATE',['EDUCATION']]         = 3\n",
    "df.loc[df['EDUCATION'] == 'UNDER GRADUATE',['EDUCATION']]   = 3\n",
    "df.loc[df['EDUCATION'] == 'POST-GRADUATE',['EDUCATION']]    = 4\n",
    "df.loc[df['EDUCATION'] == 'OTHERS',['EDUCATION']]           = 1\n",
    "df.loc[df['EDUCATION'] == 'PROFESSIONAL',['EDUCATION']]     = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cc0ff70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42064 entries, 0 to 42063\n",
      "Data columns (total 43 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   pct_tl_open_L6M            42064 non-null  float64\n",
      " 1   pct_tl_closed_L6M          42064 non-null  float64\n",
      " 2   Tot_TL_closed_L12M         42064 non-null  int64  \n",
      " 3   pct_tl_closed_L12M         42064 non-null  float64\n",
      " 4   Tot_Missed_Pmnt            42064 non-null  int64  \n",
      " 5   CC_TL                      42064 non-null  int64  \n",
      " 6   Home_TL                    42064 non-null  int64  \n",
      " 7   PL_TL                      42064 non-null  int64  \n",
      " 8   Secured_TL                 42064 non-null  int64  \n",
      " 9   Unsecured_TL               42064 non-null  int64  \n",
      " 10  Other_TL                   42064 non-null  int64  \n",
      " 11  Age_Oldest_TL              42064 non-null  int64  \n",
      " 12  Age_Newest_TL              42064 non-null  int64  \n",
      " 13  time_since_recent_payment  42064 non-null  int64  \n",
      " 14  max_recent_level_of_deliq  42064 non-null  int64  \n",
      " 15  num_deliq_6_12mts          42064 non-null  int64  \n",
      " 16  num_times_60p_dpd          42064 non-null  int64  \n",
      " 17  num_std_12mts              42064 non-null  int64  \n",
      " 18  num_sub                    42064 non-null  int64  \n",
      " 19  num_sub_6mts               42064 non-null  int64  \n",
      " 20  num_sub_12mts              42064 non-null  int64  \n",
      " 21  num_dbt                    42064 non-null  int64  \n",
      " 22  num_dbt_12mts              42064 non-null  int64  \n",
      " 23  num_lss                    42064 non-null  int64  \n",
      " 24  recent_level_of_deliq      42064 non-null  int64  \n",
      " 25  CC_enq_L12m                42064 non-null  int64  \n",
      " 26  PL_enq_L12m                42064 non-null  int64  \n",
      " 27  time_since_recent_enq      42064 non-null  int64  \n",
      " 28  enq_L3m                    42064 non-null  int64  \n",
      " 29  NETMONTHLYINCOME           42064 non-null  int64  \n",
      " 30  Time_With_Curr_Empr        42064 non-null  int64  \n",
      " 31  CC_Flag                    42064 non-null  int64  \n",
      " 32  PL_Flag                    42064 non-null  int64  \n",
      " 33  pct_PL_enq_L6m_of_ever     42064 non-null  float64\n",
      " 34  pct_CC_enq_L6m_of_ever     42064 non-null  float64\n",
      " 35  HL_Flag                    42064 non-null  int64  \n",
      " 36  GL_Flag                    42064 non-null  int64  \n",
      " 37  MARITALSTATUS              42064 non-null  object \n",
      " 38  EDUCATION                  42064 non-null  int32  \n",
      " 39  GENDER                     42064 non-null  object \n",
      " 40  last_prod_enq2             42064 non-null  object \n",
      " 41  first_prod_enq2            42064 non-null  object \n",
      " 42  Approved_Flag              42064 non-null  object \n",
      "dtypes: float64(5), int32(1), int64(32), object(5)\n",
      "memory usage: 13.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df['EDUCATION'].value_counts()\n",
    "df['EDUCATION'] = df['EDUCATION'].astype(int)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5708ac73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df, columns=['MARITALSTATUS','GENDER', 'last_prod_enq2' ,'first_prod_enq2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e02f4010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42064 entries, 0 to 42063\n",
      "Data columns (total 55 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   pct_tl_open_L6M               42064 non-null  float64\n",
      " 1   pct_tl_closed_L6M             42064 non-null  float64\n",
      " 2   Tot_TL_closed_L12M            42064 non-null  int64  \n",
      " 3   pct_tl_closed_L12M            42064 non-null  float64\n",
      " 4   Tot_Missed_Pmnt               42064 non-null  int64  \n",
      " 5   CC_TL                         42064 non-null  int64  \n",
      " 6   Home_TL                       42064 non-null  int64  \n",
      " 7   PL_TL                         42064 non-null  int64  \n",
      " 8   Secured_TL                    42064 non-null  int64  \n",
      " 9   Unsecured_TL                  42064 non-null  int64  \n",
      " 10  Other_TL                      42064 non-null  int64  \n",
      " 11  Age_Oldest_TL                 42064 non-null  int64  \n",
      " 12  Age_Newest_TL                 42064 non-null  int64  \n",
      " 13  time_since_recent_payment     42064 non-null  int64  \n",
      " 14  max_recent_level_of_deliq     42064 non-null  int64  \n",
      " 15  num_deliq_6_12mts             42064 non-null  int64  \n",
      " 16  num_times_60p_dpd             42064 non-null  int64  \n",
      " 17  num_std_12mts                 42064 non-null  int64  \n",
      " 18  num_sub                       42064 non-null  int64  \n",
      " 19  num_sub_6mts                  42064 non-null  int64  \n",
      " 20  num_sub_12mts                 42064 non-null  int64  \n",
      " 21  num_dbt                       42064 non-null  int64  \n",
      " 22  num_dbt_12mts                 42064 non-null  int64  \n",
      " 23  num_lss                       42064 non-null  int64  \n",
      " 24  recent_level_of_deliq         42064 non-null  int64  \n",
      " 25  CC_enq_L12m                   42064 non-null  int64  \n",
      " 26  PL_enq_L12m                   42064 non-null  int64  \n",
      " 27  time_since_recent_enq         42064 non-null  int64  \n",
      " 28  enq_L3m                       42064 non-null  int64  \n",
      " 29  NETMONTHLYINCOME              42064 non-null  int64  \n",
      " 30  Time_With_Curr_Empr           42064 non-null  int64  \n",
      " 31  CC_Flag                       42064 non-null  int64  \n",
      " 32  PL_Flag                       42064 non-null  int64  \n",
      " 33  pct_PL_enq_L6m_of_ever        42064 non-null  float64\n",
      " 34  pct_CC_enq_L6m_of_ever        42064 non-null  float64\n",
      " 35  HL_Flag                       42064 non-null  int64  \n",
      " 36  GL_Flag                       42064 non-null  int64  \n",
      " 37  EDUCATION                     42064 non-null  int32  \n",
      " 38  Approved_Flag                 42064 non-null  object \n",
      " 39  MARITALSTATUS_Married         42064 non-null  bool   \n",
      " 40  MARITALSTATUS_Single          42064 non-null  bool   \n",
      " 41  GENDER_F                      42064 non-null  bool   \n",
      " 42  GENDER_M                      42064 non-null  bool   \n",
      " 43  last_prod_enq2_AL             42064 non-null  bool   \n",
      " 44  last_prod_enq2_CC             42064 non-null  bool   \n",
      " 45  last_prod_enq2_ConsumerLoan   42064 non-null  bool   \n",
      " 46  last_prod_enq2_HL             42064 non-null  bool   \n",
      " 47  last_prod_enq2_PL             42064 non-null  bool   \n",
      " 48  last_prod_enq2_others         42064 non-null  bool   \n",
      " 49  first_prod_enq2_AL            42064 non-null  bool   \n",
      " 50  first_prod_enq2_CC            42064 non-null  bool   \n",
      " 51  first_prod_enq2_ConsumerLoan  42064 non-null  bool   \n",
      " 52  first_prod_enq2_HL            42064 non-null  bool   \n",
      " 53  first_prod_enq2_PL            42064 non-null  bool   \n",
      " 54  first_prod_enq2_others        42064 non-null  bool   \n",
      "dtypes: bool(16), float64(5), int32(1), int64(32), object(1)\n",
      "memory usage: 13.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_encoded.info()\n",
    "k = df_encoded.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "619d4f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.7636990372043266\n",
      "\n",
      "Class p1:\n",
      "Precision: 0.8370457209847597\n",
      "Recall: 0.7041420118343196\n",
      "F1 Score: 0.7648634172469203\n",
      "\n",
      "Class p2:\n",
      "Precision: 0.7957519116397621\n",
      "Recall: 0.9282457879088206\n",
      "F1 Score: 0.8569075937785909\n",
      "\n",
      "Class p3:\n",
      "Precision: 0.4423380726698262\n",
      "Recall: 0.21132075471698114\n",
      "F1 Score: 0.28600612870275793\n",
      "\n",
      "Class p4:\n",
      "Precision: 0.7178502879078695\n",
      "Recall: 0.7269193391642371\n",
      "F1 Score: 0.7223563495895703\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Machine Learing model fitting\n",
    "\n",
    "# Data processing\n",
    "\n",
    "# 1. Random Forest\n",
    "\n",
    "y = df_encoded['Approved_Flag']\n",
    "x = df_encoded. drop ( ['Approved_Flag'], axis = 1 )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators = 200, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rf_classifier.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "y_pred = rf_classifier.predict(x_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print ()\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print ()\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f\"Class {v}:\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")\n",
    "    print(f\"F1 Score: {f1_score[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e0edd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.78\n",
      "\n",
      "Class p1:\n",
      "Precision: 0.823906083244397\n",
      "Recall: 0.7613412228796844\n",
      "F1 Score: 0.7913890312660173\n",
      "\n",
      "Class p2:\n",
      "Precision: 0.8255418233924413\n",
      "Recall: 0.913577799801784\n",
      "F1 Score: 0.8673315769665036\n",
      "\n",
      "Class p3:\n",
      "Precision: 0.4756380510440835\n",
      "Recall: 0.30943396226415093\n",
      "F1 Score: 0.3749428440786465\n",
      "\n",
      "Class p4:\n",
      "Precision: 0.7342386032977691\n",
      "Recall: 0.7356656948493683\n",
      "F1 Score: 0.7349514563106796\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. xgboost\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier(objective='multi:softmax',  num_class=4)\n",
    "\n",
    "\n",
    "\n",
    "y = df_encoded['Approved_Flag']\n",
    "x = df_encoded. drop ( ['Approved_Flag'], axis = 1 )\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "xgb_classifier.fit(x_train, y_train)\n",
    "y_pred = xgb_classifier.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print ()\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print ()\n",
    "\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f\"Class {v}:\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")\n",
    "    print(f\"F1 Score: {f1_score[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "222bdd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.71\n",
      "\n",
      "Class p1:\n",
      "Precision: 0.7290836653386454\n",
      "Recall: 0.7218934911242604\n",
      "F1 Score: 0.7254707631318138\n",
      "\n",
      "Class p2:\n",
      "Precision: 0.8095238095238095\n",
      "Recall: 0.8289395441030724\n",
      "F1 Score: 0.8191166389188131\n",
      "\n",
      "Class p3:\n",
      "Precision: 0.3413269384492406\n",
      "Recall: 0.3222641509433962\n",
      "F1 Score: 0.33152173913043476\n",
      "\n",
      "Class p4:\n",
      "Precision: 0.6491935483870968\n",
      "Recall: 0.6258503401360545\n",
      "F1 Score: 0.6373082632360217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "y = df_encoded['Approved_Flag']\n",
    "x = df_encoded. drop ( ['Approved_Flag'], axis = 1 )\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "dt_model = DecisionTreeClassifier(max_depth=20, min_samples_split=10)\n",
    "dt_model.fit(x_train, y_train)\n",
    "y_pred = dt_model.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print ()\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print ()\n",
    "\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f\"Class {v}:\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")\n",
    "    print(f\"F1 Score: {f1_score[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ec73e2",
   "metadata": {},
   "source": [
    "#### xgboost is giving me best results\n",
    "#### We will further finetune it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f1e3409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply standard scaler \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "columns_to_be_scaled = ['Age_Oldest_TL','Age_Newest_TL','time_since_recent_payment',\n",
    "'max_recent_level_of_deliq','recent_level_of_deliq',\n",
    "'time_since_recent_enq','NETMONTHLYINCOME','Time_With_Curr_Empr']\n",
    "\n",
    "for i in columns_to_be_scaled:\n",
    "    column_data = df_encoded[i].values.reshape(-1, 1)\n",
    "    scaler = StandardScaler()\n",
    "    scaled_column = scaler.fit_transform(column_data)\n",
    "    df_encoded[i] = scaled_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d76869a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78\n",
      "Class p1:\n",
      "Precision: 0.823906083244397\n",
      "Recall: 0.7613412228796844\n",
      "F1 Score: 0.7913890312660173\n",
      "\n",
      "Class p2:\n",
      "Precision: 0.8255418233924413\n",
      "Recall: 0.913577799801784\n",
      "F1 Score: 0.8673315769665036\n",
      "\n",
      "Class p3:\n",
      "Precision: 0.4756380510440835\n",
      "Recall: 0.30943396226415093\n",
      "F1 Score: 0.3749428440786465\n",
      "\n",
      "Class p4:\n",
      "Precision: 0.7342386032977691\n",
      "Recall: 0.7356656948493683\n",
      "F1 Score: 0.7349514563106796\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier(objective='multi:softmax',  num_class=4)\n",
    "\n",
    "\n",
    "\n",
    "y = df_encoded['Approved_Flag']\n",
    "x = df_encoded. drop ( ['Approved_Flag'], axis = 1 )\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "xgb_classifier.fit(x_train, y_train)\n",
    "y_pred = xgb_classifier.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f\"Class {v}:\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")\n",
    "    print(f\"F1 Score: {f1_score[i]}\")\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8fce198d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning in xgboost\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the XGBClassifier with the initial set of hyperparameters\n",
    "xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=4)\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b7ab0ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7811719957209081\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model with the best hyperparameters on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "accuracy = best_model.score(x_test, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Best Hyperparameters: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200}\n",
    "\n",
    "\n",
    "# Based on risk appetite of the bank, you will suggest P1,P2,P3,P4 to the business end user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9449dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Define the hyperparameter grid\n",
    "# param_grid = {\n",
    "#   'colsample_bytree': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "#   'learning_rate'   : [0.001, 0.01, 0.1, 1],\n",
    "#   'max_depth'       : [3, 5, 8, 10],\n",
    "#   'alpha'           : [1, 10, 100],\n",
    "#   'n_estimators'    : [10,50,100]\n",
    "# }\n",
    "\n",
    "# index = 0\n",
    "\n",
    "# answers_grid = {\n",
    "#     'combination'       :[],\n",
    "#     'train_Accuracy'    :[],\n",
    "#     'test_Accuracy'     :[],\n",
    "#     'colsample_bytree'  :[],\n",
    "#     'learning_rate'     :[],\n",
    "#     'max_depth'         :[],\n",
    "#     'alpha'             :[],\n",
    "#     'n_estimators'      :[]\n",
    "\n",
    "#     }\n",
    "\n",
    "\n",
    "# # Loop through each combination of hyperparameters\n",
    "# for colsample_bytree in param_grid['colsample_bytree']:\n",
    "#   for learning_rate in param_grid['learning_rate']:\n",
    "#     for max_depth in param_grid['max_depth']:\n",
    "#       for alpha in param_grid['alpha']:\n",
    "#           for n_estimators in param_grid['n_estimators']:\n",
    "             \n",
    "#               index = index + 1\n",
    "             \n",
    "#               # Define and train the XGBoost model\n",
    "#               model = xgb.XGBClassifier(objective='multi:softmax',  \n",
    "#                                        num_class=4,\n",
    "#                                        colsample_bytree = colsample_bytree,\n",
    "#                                        learning_rate = learning_rate,\n",
    "#                                        max_depth = max_depth,\n",
    "#                                        alpha = alpha,\n",
    "#                                        n_estimators = n_estimators)\n",
    "               \n",
    "       \n",
    "                     \n",
    "#               y = df_encoded['Approved_Flag']\n",
    "#               x = df_encoded. drop ( ['Approved_Flag'], axis = 1 )\n",
    "\n",
    "#               label_encoder = LabelEncoder()\n",
    "#               y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "#               x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "#               model.fit(x_train, y_train)\n",
    "  \n",
    "\n",
    "       \n",
    "#               # Predict on training and testing sets\n",
    "#               y_pred_train = model.predict(x_train)\n",
    "#               y_pred_test = model.predict(x_test)\n",
    "       \n",
    "       \n",
    "#               # Calculate train and test results\n",
    "              \n",
    "#               train_accuracy =  accuracy_score (y_train, y_pred_train)\n",
    "#               test_accuracy  =  accuracy_score (y_test , y_pred_test)\n",
    "              \n",
    "              \n",
    "       \n",
    "#               Include into the lists\n",
    "#               answers_grid ['combination']   .append(index)\n",
    "#               answers_grid ['train_Accuracy']    .append(train_accuracy)\n",
    "#               answers_grid ['test_Accuracy']     .append(test_accuracy)\n",
    "#               answers_grid ['colsample_bytree']   .append(colsample_bytree)\n",
    "#               answers_grid ['learning_rate']      .append(learning_rate)\n",
    "#               answers_grid ['max_depth']          .append(max_depth)\n",
    "#               answers_grid ['alpha']              .append(alpha)\n",
    "#               answers_grid ['n_estimators']       .append(n_estimators)\n",
    "       \n",
    "       \n",
    "#               # Print results for this combination\n",
    "#               print(f\"Combination {index}\")\n",
    "#               print(f\"colsample_bytree: {colsample_bytree}, learning_rate: {learning_rate}, max_depth: {max_depth}, alpha: {alpha}, n_estimators: {n_estimators}\")\n",
    "#               print(f\"Train Accuracy: {train_accuracy:.2f}\")\n",
    "#               print(f\"Test Accuracy : {test_accuracy :.2f}\")\n",
    "#               print(\"-\" * 30)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
